torchrun --nproc_per_node 1 pretrain_mamba.py --micro-batch-size 4 --num-layer 4 --hidden-size 2048 --num-attention-heads 8 --max-position-embeddings 1024 --encoder-seq-length 1024 --vocab-file /workspace/megatron/dataset/vocab.json --merge-file /workspace/megatron/dataset/merges.txt --num-workers 1 --spec megatron.core.models.mamba.mamba.mamba_layer_specs mamba_stack_spec --train-iters 10 --lr 2.5e-4 --mock-data


ncu --cache-control none   --csv  --nvtx --nvtx-include "forward/"  --metrics  gpu__time_duration,sm__cycles_active,lts__t_sector_hit_rate.pct,l1tex__t_sector_hit_rate.pct,sm__inst_executed_pipe_adu,sm__inst_executed_pipe_alu,sm__inst_executed_pipe_cbu,sm__inst_executed_pipe_cbu_pred_off_all,sm__inst_executed_pipe_cbu_pred_on_any,sm__inst_executed_pipe_fmaheavy,sm__inst_executed_pipe_fmalite,sm__inst_executed_pipe_fp64,sm__inst_executed_pipe_ipa,sm__inst_executed_pipe_lsu,sm__inst_executed_pipe_tensor,sm__inst_executed_pipe_tensor_op_dmma,sm__inst_executed_pipe_tensor_op_gmma,sm__inst_executed_pipe_tensor_op_hmma,sm__inst_executed_pipe_tensor_op_hmma_type_hfma2,sm__inst_executed_pipe_tensor_op_imma,sm__inst_executed_pipe_tex,sm__inst_executed_pipe_tma,sm__inst_executed_pipe_tma_pred_off_all,sm__inst_executed_pipe_tma_pred_on_any,sm__inst_executed_pipe_uniform,sm__inst_executed_pipe_xu,sm__inst_executed_pipe_xu_realtime,sm__thread_inst_executed_pipe_fma_pred_on,sm__thread_inst_executed_pipe_fmaheavy_pred_on,sm__thread_inst_executed_pipe_fmalite_pred_on,smsp__inst_executed_pipe_adu,smsp__inst_executed_pipe_alu,smsp__inst_executed_pipe_cbu,smsp__inst_executed_pipe_cbu_pred_off_all,smsp__inst_executed_pipe_cbu_pred_on_any,smsp__inst_executed_pipe_fmaheavy,smsp__inst_executed_pipe_fmalite,smsp__inst_executed_pipe_fp64,smsp__inst_executed_pipe_ipa,smsp__inst_executed_pipe_lsu,smsp__inst_executed_pipe_tensor,smsp__inst_executed_pipe_tensor_op_dmma,smsp__inst_executed_pipe_tensor_op_gmma,smsp__inst_executed_pipe_tensor_op_hmma,smsp__inst_executed_pipe_tensor_op_hmma_type_hfma2,smsp__inst_executed_pipe_tensor_op_imma,smsp__inst_executed_pipe_tex,smsp__inst_executed_pipe_tma,smsp__inst_executed_pipe_tma_pred_off_all,smsp__inst_executed_pipe_tma_pred_on_any,smsp__inst_executed_pipe_uniform,smsp__inst_executed_pipe_xu,smsp__thread_inst_executed_pipe_fma_pred_on,smsp__thread_inst_executed_pipe_fmaheavy_pred_on,smsp__thread_inst_executed_pipe_fmalite_pred_on,dram__bytes,dram__bytes_read,dram__bytes_write,sm__throughput.avg.pct_of_peak_sustained_elapsed,gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed torchrun --nproc_per_node 1 pretrain_mamba.py --micro-batch-size 4 --num-layers 8 --hidden-size 4096 --num-attention-heads 32 --max-position-embeddings 4096 --encoder-seq-length 4096 --vocab-file /workspace/megatron/dataset/vocab.json --merge-file /workspace/megatron/dataset/merges.txt --num-workers 1 --bf16  --spec megatron.core.models.mamba.mamba_layer_specs mamba_stack_spec --train-iters 30 --lr 2.5e-4 --data-path /workspace/megatron/dataset/output/bookcorpus_0_text_sentence > mamba_forward.csv



#Only required metrics

ncu --cache-control none --csv --nvtx --nvtx-include "forward/"  --nvtx-push-pop-scope process --metrics  lts__throughput.avg.pct_of_peak_sustained_elapsed,l1tex__throughput.avg.pct_of_peak_sustained_active,gpu__time_duration,sm__cycles_active,lts__t_sector_hit_rate.pct,l1tex__t_sector_hit_rate.pct,sm__inst_executed_pipe_adu,sm__inst_executed_pipe_alu,sm__inst_executed_pipe_cbu,sm__inst_executed_pipe_cbu_pred_off_all,sm__inst_executed_pipe_cbu_pred_on_any,sm__inst_executed_pipe_fmaheavy,sm__inst_executed_pipe_fmalite,sm__inst_executed_pipe_fp64,sm__inst_executed_pipe_ipa,sm__inst_executed_pipe_lsu,sm__inst_executed_pipe_tensor,sm__inst_executed_pipe_tensor_op_dmma,sm__inst_executed_pipe_tensor_op_gmma,sm__inst_executed_pipe_tensor_op_hmma,sm__inst_executed_pipe_tensor_op_hmma_type_hfma2,sm__inst_executed_pipe_tensor_op_imma,sm__inst_executed_pipe_tex,sm__inst_executed_pipe_tma,sm__inst_executed_pipe_tma_pred_off_all,sm__inst_executed_pipe_tma_pred_on_any,sm__inst_executed_pipe_uniform,sm__inst_executed_pipe_xu,sm__inst_executed_pipe_xu_realtime,sm__thread_inst_executed_pipe_fma_pred_on,sm__thread_inst_executed_pipe_fmaheavy_pred_on,sm__thread_inst_executed_pipe_fmalite_pred_on,dram__bytes,dram__bytes_read,dram__bytes_write,sm__throughput.avg.pct_of_peak_sustained_elapsed,gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed torchrun --nproc_per_node 1 pretrain_mamba.py --micro-batch-size 4 --num-layers 8 --hidden-size 4096 --num-attention-heads 32 --max-position-embeddings 4096 --encoder-seq-length 4096 --vocab-file /workspace/megatron/dataset/vocab.json --merge-file /workspace/megatron/dataset/merges.txt --num-workers 1 --bf16 --spec megatron.core.models.mamba.mamba_layer_specs mamba_stack_spec --train-iters 30 --lr 2.5e-4 --data-path /workspace/megatron/dataset/output/bookcorpus_0_text_sentence > mamba_standalone_forward.csv


ncu --nvtx --nvtx-include "forward/" --nvtx-push-pop-scope process --page source -f -o  mamba_kernels torchrun --nproc_per_node 1 pretrain_mamba.py --micro-batch-size 4 --num-layers 8 --hidden-size 4096 --num-attention-heads 32 --max-position-embeddings 4096 --encoder-seq-length 4096 --vocab-file /workspace/megatron/dataset/vocab.json --merge-file /workspace/megatron/dataset/merges.txt --num-workers 1 --bf16 --spec megatron.core.models.mamba.mamba_layer_specs mamba_stack_spec --train-iters 30 --lr 2.5e-4 --data-path /workspace/megatron/dataset/output/bookcorpus_0_text_sentence 


ncu --import mamba_kernels.ncu-rep --print-source sass --page source > kernels.txt



#Hybrid attention

ncu --cache-control none --csv --nvtx --nvtx-include "forward/"  --nvtx-push-pop-scope process --metrics  lts__throughput.avg.pct_of_peak_sustained_elapsed,l1tex__throughput.avg.pct_of_peak_sustained_active,gpu__time_duration,sm__cycles_active,lts__t_sector_hit_rate.pct,l1tex__t_sector_hit_rate.pct,sm__inst_executed_pipe_adu,sm__inst_executed_pipe_alu,sm__inst_executed_pipe_cbu,sm__inst_executed_pipe_cbu_pred_off_all,sm__inst_executed_pipe_cbu_pred_on_any,sm__inst_executed_pipe_fmaheavy,sm__inst_executed_pipe_fmalite,sm__inst_executed_pipe_fp64,sm__inst_executed_pipe_ipa,sm__inst_executed_pipe_lsu,sm__inst_executed_pipe_tensor,sm__inst_executed_pipe_tensor_op_dmma,sm__inst_executed_pipe_tensor_op_gmma,sm__inst_executed_pipe_tensor_op_hmma,sm__inst_executed_pipe_tensor_op_hmma_type_hfma2,sm__inst_executed_pipe_tensor_op_imma,sm__inst_executed_pipe_tex,sm__inst_executed_pipe_tma,sm__inst_executed_pipe_tma_pred_off_all,sm__inst_executed_pipe_tma_pred_on_any,sm__inst_executed_pipe_uniform,sm__inst_executed_pipe_xu,sm__inst_executed_pipe_xu_realtime,sm__thread_inst_executed_pipe_fma_pred_on,sm__thread_inst_executed_pipe_fmaheavy_pred_on,sm__thread_inst_executed_pipe_fmalite_pred_on,dram__bytes,dram__bytes_read,dram__bytes_write,sm__throughput.avg.pct_of_peak_sustained_elapsed,gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed torchrun --nproc_per_node 1 pretrain_mamba.py --micro-batch-size 4 --num-layers 16 --hybrid-attention-ratio 0.07 --hybrid-mlp-ratio 0.5  --hidden-size 4096 --num-attention-heads 32 --max-position-embeddings 4096 --encoder-seq-length 4096 --vocab-file /workspace/megatron/dataset/vocab.json --merge-file /workspace/megatron/dataset/merges.txt --num-workers 1 --bf16 --spec megatron.core.models.mamba.mamba_layer_specs mamba_stack_spec --train-iters 30 --lr 2.5e-4 --attention-backend flash  --data-path /workspace/megatron/dataset/output/bookcorpus_0_text_sentence > mamba_hybrid_forward_backward.csv

#Ignore below
ncu --csv  --metrics  lts__t_sector_hit_rate.pct,l1tex__t_sector_hit_rate.pct,sm__inst_executed_pipe_adu,sm__inst_executed_pipe_alu,sm__inst_executed_pipe_cbu,sm__inst_executed_pipe_cbu_pred_off_all,sm__inst_executed_pipe_cbu_pred_on_any,sm__inst_executed_pipe_fmaheavy,sm__inst_executed_pipe_fmalite,sm__inst_executed_pipe_fp64,sm__inst_executed_pipe_ipa,sm__inst_executed_pipe_lsu,sm__inst_executed_pipe_tensor,sm__inst_executed_pipe_tensor_op_dmma,sm__inst_executed_pipe_tensor_op_gmma,sm__inst_executed_pipe_tensor_op_hmma,sm__inst_executed_pipe_tensor_op_hmma_type_hfma2,sm__inst_executed_pipe_tensor_op_imma,sm__inst_executed_pipe_tex,sm__inst_executed_pipe_tma,sm__inst_executed_pipe_tma_pred_off_all,sm__inst_executed_pipe_tma_pred_on_any,sm__inst_executed_pipe_uniform,sm__inst_executed_pipe_xu,sm__inst_executed_pipe_xu_realtime,sm__thread_inst_executed_pipe_fma_pred_on,sm__thread_inst_executed_pipe_fmaheavy_pred_on,sm__thread_inst_executed_pipe_fmalite_pred_on,smsp__inst_executed_pipe_adu,smsp__inst_executed_pipe_alu,smsp__inst_executed_pipe_cbu,smsp__inst_executed_pipe_cbu_pred_off_all,smsp__inst_executed_pipe_cbu_pred_on_any,smsp__inst_executed_pipe_fmaheavy,smsp__inst_executed_pipe_fmalite,smsp__inst_executed_pipe_fp64,smsp__inst_executed_pipe_ipa,smsp__inst_executed_pipe_lsu,smsp__inst_executed_pipe_tensor,smsp__inst_executed_pipe_tensor_op_dmma,smsp__inst_executed_pipe_tensor_op_gmma,smsp__inst_executed_pipe_tensor_op_hmma,smsp__inst_executed_pipe_tensor_op_hmma_type_hfma2,smsp__inst_executed_pipe_tensor_op_imma,smsp__inst_executed_pipe_tex,smsp__inst_executed_pipe_tma,smsp__inst_executed_pipe_tma_pred_off_all,smsp__inst_executed_pipe_tma_pred_on_any,smsp__inst_executed_pipe_uniform,smsp__inst_executed_pipe_xu,smsp__thread_inst_executed_pipe_fma_pred_on,smsp__thread_inst_executed_pipe_fmaheavy_pred_on,smsp__thread_inst_executed_pipe_fmalite_pred_on,dram__bytes,dram__bytes_read,dram__bytes_write,sm__throughput.avg.pct_of_peak_sustained_elapsed,gpu__compute_memory_throughput.avg.pct_of_peak_sustained_elapsed torchrun --nproc_per_node 1 pretrain_mamba.py --micro-batch-size 4 --num-layers 8 --hidden-size 4096 --num-attention-heads 32 --max-position-embeddings 4096 --encoder-seq-length 4096 --vocab-file /workspace/megatron/dataset/vocab.json --merge-file /workspace/megatron/dataset/merges.txt --num-workers 1 --bf16  --spec megatron.core.models.mamba.mamba_layer_specs mamba_stack_spec --train-iters 30 --lr 2.5e-4 --data-path /workspace/megatron/dataset/output/bookcorpus_0_text_sentence > mamba_standalone.csv
